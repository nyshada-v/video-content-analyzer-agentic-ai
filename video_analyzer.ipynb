{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EIFzA7zTbeFH"
      },
      "outputs": [],
      "source": [
        "# Install required libraries\n",
        "!pip install gradio\n",
        "!pip install openai\n",
        "!pip install chromadb\n",
        "!pip install moviepy\n",
        "!pip install opencv-python\n",
        "!pip install python-dotenv\n",
        "!pip install langchain\n",
        "!pip install langchain-openai\n",
        "!pip install tiktoken\n",
        "\n",
        "print(\"âœ… All libraries installed successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cONLGt3grvk0"
      },
      "outputs": [],
      "source": [
        "!pip install -U google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRpz8aIwpdlc",
        "outputId": "5362bd63-c1b3-4dd5-a59e-26ba40aacc90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… API keys loaded from secrets!\n"
          ]
        }
      ],
      "source": [
        "# Load API keys from Colab Secrets (persists across sessions!)\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')\n",
        "os.environ[\"ASSEMBLYAI_API_KEY\"] = userdata.get('ASSEMBLYAI_API_KEY')\n",
        "\n",
        "print(\"âœ… API keys loaded from secrets!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-P7sNBCprn5",
        "outputId": "5bde661c-bf00-4e57-c111-1368bc18a52d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/51.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m51.6/51.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hâœ… Gemini and AssemblyAI libraries installed!\n"
          ]
        }
      ],
      "source": [
        "# Install Gemini and AssemblyAI libraries\n",
        "!pip install -q google-generativeai\n",
        "!pip install -q assemblyai\n",
        "\n",
        "print(\"âœ… Gemini and AssemblyAI libraries installed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "0LS-Hg53uzGL",
        "outputId": "fc0e3407-c5ba-4d90-efee-bff4b89b5856"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ”§ Setting up APIs...\n",
            "\n",
            "âœ… API keys loaded from Colab secrets\n",
            "âœ… Gemini API Test:\n",
            "Gemini API is working!\n",
            "\n",
            "\n",
            "âœ… AssemblyAI API: Connected successfully!\n",
            "\n",
            "ğŸ‰ Setup complete! Ready to build!\n"
          ]
        }
      ],
      "source": [
        "# Final working version for Google Colab - WITH COLAB SECRETS\n",
        "import google.generativeai as genai\n",
        "import assemblyai as aai\n",
        "import os\n",
        "from google.colab import userdata  # Add this import\n",
        "\n",
        "print(\"ğŸ”§ Setting up APIs...\\n\")\n",
        "\n",
        "# Configure APIs with Colab Secrets\n",
        "try:\n",
        "    # Load from Colab secrets\n",
        "    GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "    ASSEMBLYAI_API_KEY = userdata.get('ASSEMBLYAI_API_KEY')\n",
        "\n",
        "    print(\"âœ… API keys loaded from Colab secrets\")\n",
        "\n",
        "    # Configure Gemini API\n",
        "    genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "    # Test Gemini API\n",
        "    try:\n",
        "        model = genai.GenerativeModel('models/gemini-2.0-flash')\n",
        "        response = model.generate_content(\"Say 'Gemini API is working!'\")\n",
        "        print(\"âœ… Gemini API Test:\")\n",
        "        print(response.text)\n",
        "        print()\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Gemini Error: {e}\")\n",
        "        print(\"\\nTrying alternative model...\")\n",
        "        try:\n",
        "            model = genai.GenerativeModel('models/gemini-1.5-flash')\n",
        "            response = model.generate_content(\"Say 'Gemini API is working!'\")\n",
        "            print(\"âœ… Gemini API Test (with gemini-1.5-flash):\")\n",
        "            print(response.text)\n",
        "            print()\n",
        "        except Exception as e2:\n",
        "            print(f\"âŒ Still error: {e2}\\n\")\n",
        "\n",
        "    # Test AssemblyAI API\n",
        "    try:\n",
        "        aai.settings.api_key = ASSEMBLYAI_API_KEY\n",
        "        transcriber = aai.Transcriber()\n",
        "        print(\"âœ… AssemblyAI API: Connected successfully!\")\n",
        "        print()\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ AssemblyAI Error: {e}\\n\")\n",
        "\n",
        "    print(\"ğŸ‰ Setup complete! Ready to build!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Error loading API keys: {e}\")\n",
        "    print(\"\\nğŸ’¡ Make sure you've set up Colab secrets:\")\n",
        "    print(\"1. Click the ğŸ”‘ key icon in left sidebar\")\n",
        "    print(\"2. Add two secrets:\")\n",
        "    print(\"   - Name: GOOGLE_API_KEY, Value: your_gemini_api_key\")\n",
        "    print(\"   - Name: ASSEMBLYAI_API_KEY, Value: your_assemblyai_api_key\")\n",
        "    print(\"3. Restart runtime and run this cell again\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XFCAOdGt7ONd",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Upload video here\n",
        "# Create a sample upload area\n",
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "print(\"ğŸ“¹ Upload a test video file (MP4, MOV, AVI, etc.)\")\n",
        "print(\"Recommended: A short video (1-3 minutes) for testing\\n\")\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Get the uploaded filename\n",
        "video_filename = list(uploaded.keys())[0]\n",
        "print(f\"\\nâœ… Video uploaded: {video_filename}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFP_zMq2huV7",
        "outputId": "eb64f8e5-e638-44e1-e615-4143523ab20a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting assemblyai\n",
            "  Downloading assemblyai-0.45.5-py3-none-any.whl.metadata (27 kB)\n",
            "Requirement already satisfied: httpx>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from assemblyai) (0.28.1)\n",
            "Requirement already satisfied: pydantic>=1.10.17 in /usr/local/lib/python3.12/dist-packages (from assemblyai) (2.11.10)\n",
            "Requirement already satisfied: typing-extensions>=3.7 in /usr/local/lib/python3.12/dist-packages (from assemblyai) (4.15.0)\n",
            "Requirement already satisfied: websockets>=11.0 in /usr/local/lib/python3.12/dist-packages (from assemblyai) (15.0.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.19.0->assemblyai) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.19.0->assemblyai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.19.0->assemblyai) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.19.0->assemblyai) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.19.0->assemblyai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.10.17->assemblyai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.10.17->assemblyai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.10.17->assemblyai) (0.4.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.19.0->assemblyai) (1.3.1)\n",
            "Downloading assemblyai-0.45.5-py3-none-any.whl (51 kB)\n",
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/51.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m51.6/51.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: assemblyai\n",
            "Successfully installed assemblyai-0.45.5\n"
          ]
        }
      ],
      "source": [
        "!pip install assemblyai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07UMr3mh7ymG",
        "outputId": "6d4ffdae-0316-40bd-ca57-98db3832fc70",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… AssemblyAI API key loaded from Colab secrets\n",
            "âœ… Transcription Agent initialized\n",
            "\n",
            "ğŸ¯ Transcription Agent ready to use!\n"
          ]
        }
      ],
      "source": [
        "#@title Transcript Agent\n",
        "# AGENT 1: Transcription Agent\n",
        "import assemblyai as aai\n",
        "from moviepy.editor import VideoFileClip\n",
        "import os\n",
        "from google.colab import userdata  # Add this import\n",
        "\n",
        "class TranscriptionAgent:\n",
        "    def __init__(self, assemblyai_api_key):\n",
        "        \"\"\"Initialize the Transcription Agent\"\"\"\n",
        "        aai.settings.api_key = assemblyai_api_key\n",
        "        self.transcriber = aai.Transcriber()\n",
        "        print(\"âœ… Transcription Agent initialized\")\n",
        "\n",
        "    def extract_audio(self, video_path):\n",
        "        \"\"\"Extract audio from video file\"\"\"\n",
        "        try:\n",
        "            print(f\"ğŸ¬ Extracting audio from: {video_path}\")\n",
        "            video = VideoFileClip(video_path)\n",
        "            audio_path = \"extracted_audio.mp3\"\n",
        "            video.audio.write_audiofile(audio_path, verbose=False, logger=None)\n",
        "            video.close()\n",
        "            print(f\"âœ… Audio extracted: {audio_path}\")\n",
        "            return audio_path\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Audio extraction error: {e}\")\n",
        "            return None\n",
        "\n",
        "    def transcribe_audio(self, audio_path):\n",
        "        \"\"\"Transcribe audio file using AssemblyAI\"\"\"\n",
        "        try:\n",
        "            print(f\"ğŸ¤ Transcribing audio... (this may take a minute)\")\n",
        "\n",
        "            config = aai.TranscriptionConfig(\n",
        "                speech_model=aai.SpeechModel.best,\n",
        "                punctuate=True,\n",
        "                format_text=True\n",
        "            )\n",
        "\n",
        "            transcript = self.transcriber.transcribe(audio_path, config=config)\n",
        "\n",
        "            if transcript.status == aai.TranscriptStatus.error:\n",
        "                print(f\"âŒ Transcription error: {transcript.error}\")\n",
        "                return None\n",
        "\n",
        "            print(\"âœ… Transcription complete!\")\n",
        "            return {\n",
        "                'text': transcript.text,\n",
        "                'words': transcript.words,\n",
        "                'duration': transcript.audio_duration\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Transcription error: {e}\")\n",
        "            return None\n",
        "\n",
        "    def process_video(self, video_path):\n",
        "        \"\"\"Complete workflow: extract audio + transcribe\"\"\"\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"ğŸ¤– TRANSCRIPTION AGENT STARTED\")\n",
        "        print(\"=\"*50 + \"\\n\")\n",
        "\n",
        "        # Step 1: Extract audio\n",
        "        audio_path = self.extract_audio(video_path)\n",
        "        if not audio_path:\n",
        "            return None\n",
        "\n",
        "        # Step 2: Transcribe\n",
        "        result = self.transcribe_audio(audio_path)\n",
        "\n",
        "        if result:\n",
        "            print(f\"\\nğŸ“Š Transcription Stats:\")\n",
        "            print(f\"   Duration: {result['duration']/1000:.1f} seconds\")\n",
        "            print(f\"   Words: {len(result['words'])}\")\n",
        "            print(f\"   Characters: {len(result['text'])}\")\n",
        "            print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "        return result\n",
        "\n",
        "# Initialize the agent - FIXED VERSION\n",
        "try:\n",
        "    # Method 1: Using Colab userdata (recommended)\n",
        "    ASSEMBLYAI_API_KEY = userdata.get('ASSEMBLYAI_API_KEY')\n",
        "    print(\"âœ… AssemblyAI API key loaded from Colab secrets\")\n",
        "except Exception as e:\n",
        "    try:\n",
        "        # Method 2: Traditional environment variable\n",
        "        ASSEMBLYAI_API_KEY = os.environ[\"ASSEMBLYAI_API_KEY\"]\n",
        "        print(\"âœ… AssemblyAI API key loaded from environment variable\")\n",
        "    except:\n",
        "        print(\"âŒ Could not load AssemblyAI API key. Please check your Colab secrets.\")\n",
        "        ASSEMBLYAI_API_KEY = None\n",
        "\n",
        "if ASSEMBLYAI_API_KEY:\n",
        "    transcription_agent = TranscriptionAgent(ASSEMBLYAI_API_KEY)\n",
        "    print(\"\\nğŸ¯ Transcription Agent ready to use!\")\n",
        "else:\n",
        "    print(\"\\nâš ï¸  Please set up your ASSEMBLYAI_API_KEY in Colab secrets first!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00SVmsKj-Q6Q",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title write the transcript to file\n",
        "# Test the Transcription Agent\n",
        "result = transcription_agent.process_video(video_filename)\n",
        "\n",
        "if result:\n",
        "    print(\"\\nğŸ“ TRANSCRIPT PREVIEW (first 500 characters):\")\n",
        "    print(\"-\" * 50)\n",
        "    print(result['text'][:500] + \"...\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # Save full transcript\n",
        "    with open('transcript.txt', 'w') as f:\n",
        "        f.write(result['text'])\n",
        "    print(\"\\nğŸ’¾ Full transcript saved to: transcript.txt\")\n",
        "else:\n",
        "    print(\"\\nâŒ Transcription failed. Please check the error messages above.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0FsLSBFkBkT",
        "outputId": "fb1d987d-83ec-4573-907e-e32a2f49b44f",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Google API key loaded from Colab secrets\n",
            "âœ… Summary Agent initialized\n",
            "\n",
            "ğŸ¯ Summary Agent ready to use!\n"
          ]
        }
      ],
      "source": [
        "#@title AGENT 2: Summary Agent\n",
        "import google.generativeai as genai\n",
        "import os\n",
        "from google.colab import userdata  # Add this import\n",
        "\n",
        "class SummaryAgent:\n",
        "    def __init__(self, gemini_api_key):\n",
        "        \"\"\"Initialize the Summary Agent with Gemini\"\"\"\n",
        "        genai.configure(api_key=gemini_api_key)\n",
        "        self.model = genai.GenerativeModel('models/gemini-2.0-flash')\n",
        "        print(\"âœ… Summary Agent initialized\")\n",
        "\n",
        "    def generate_summary(self, transcript_text):\n",
        "        \"\"\"Generate a comprehensive summary of the transcript.\"\"\"\n",
        "        try:\n",
        "            print(\"\\n\" + \"=\"*50)\n",
        "            print(\"ğŸ¤– SUMMARY AGENT STARTED\")\n",
        "            print(\"=\"*50 + \"\\n\")\n",
        "\n",
        "            print(\"ğŸ“ Analyzing transcript and generating summary...\")\n",
        "\n",
        "            prompt = f\"\"\"\n",
        "            Analyze the following video transcript and provide:\n",
        "\n",
        "            1. **Main Topic**: What is this video about? (1-2 sentences)\n",
        "            2. **Key Points**: List the 5-7 most important points discussed (bullet points)\n",
        "            3. **Brief Summary**: A concise 2-3 paragraph summary of the entire content. can be less if video is short\n",
        "            4. **Key Takeaways**: 3-5 actionable insights or conclusions\n",
        "\n",
        "            Transcript:\n",
        "            {transcript_text}\n",
        "\n",
        "            Format your response clearly with headers for each section. and use bold wherever required.\n",
        "            \"\"\"\n",
        "\n",
        "            response = self.model.generate_content(prompt)\n",
        "\n",
        "            print(\"âœ… Summary generated successfully!\\n\")\n",
        "            print(\"=\"*50)\n",
        "\n",
        "            return response.text\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Summary generation error: {e}\")\n",
        "            return None\n",
        "\n",
        "    def generate_chapter_markers(self, transcript_text):\n",
        "        \"\"\"Generate chapter markers/timestamps for the video\"\"\"\n",
        "        try:\n",
        "            print(\"\\nğŸ“Œ Generating chapter markers...\")\n",
        "\n",
        "            prompt = f\"\"\"\n",
        "            Based on this video transcript, identify the main topics/sections discussed.\n",
        "            Use bold to highlight info.\n",
        "            Create chapter markers with:\n",
        "            - Chapter title (concise, descriptive)\n",
        "            - Brief description (1 sentence)\n",
        "\n",
        "            Since we don't have exact timestamps, suggest logical breakpoints.\n",
        "            Create 3-5 chapters depending on content.\n",
        "\n",
        "            Transcript:\n",
        "            {transcript_text}\n",
        "\n",
        "            Format as:\n",
        "            Chapter 1: [Title]\n",
        "            - Description: [1 sentence]\n",
        "\n",
        "            Chapter 2: [Title]\n",
        "            - Description: [1 sentence]\n",
        "\n",
        "            (etc.)\n",
        "            \"\"\"\n",
        "\n",
        "            response = self.model.generate_content(prompt)\n",
        "\n",
        "            print(\"âœ… Chapter markers generated!\\n\")\n",
        "\n",
        "            return response.text\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Chapter marker error: {e}\")\n",
        "            return None\n",
        "\n",
        "    def process_transcript(self, transcript_text):\n",
        "        \"\"\"Complete workflow: generate summary + chapter markers\"\"\"\n",
        "        # Generate summary\n",
        "        summary = self.generate_summary(transcript_text)\n",
        "\n",
        "        # Generate chapters\n",
        "        chapters = self.generate_chapter_markers(transcript_text)\n",
        "\n",
        "        return {\n",
        "            'summary': summary,\n",
        "            'chapters': chapters\n",
        "        }\n",
        "\n",
        "# Initialize the Summary Agent - FIXED VERSION\n",
        "try:\n",
        "    # Method 1: Using Colab userdata (recommended)\n",
        "    GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "    print(\"âœ… Google API key loaded from Colab secrets\")\n",
        "except Exception as e:\n",
        "    try:\n",
        "        # Method 2: Traditional environment variable\n",
        "        GOOGLE_API_KEY = os.environ[\"GOOGLE_API_KEY\"]\n",
        "        print(\"âœ… Google API key loaded from environment variable\")\n",
        "    except:\n",
        "        print(\"âŒ Could not load Google API key. Please check your Colab secrets.\")\n",
        "        GOOGLE_API_KEY = None\n",
        "\n",
        "if GOOGLE_API_KEY:\n",
        "    summary_agent = SummaryAgent(GOOGLE_API_KEY)\n",
        "    print(\"\\nğŸ¯ Summary Agent ready to use!\")\n",
        "else:\n",
        "    print(\"\\nâš ï¸  Please set up your GOOGLE_API_KEY in Colab secrets first!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LoxrxkdVmdnr",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Test the Summary Agent with the transcript we generated\n",
        "with open('transcript.txt', 'r') as f:\n",
        "    transcript = f.read()\n",
        "\n",
        "# Generate summary and chapters\n",
        "results = summary_agent.process_transcript(transcript)\n",
        "\n",
        "# Display results\n",
        "if results['summary']:\n",
        "    print(\"\\nğŸ“Š SUMMARY:\")\n",
        "    print(\"=\"*60)\n",
        "    print(results['summary'])\n",
        "    print(\"=\"*60)\n",
        "\n",
        "if results['chapters']:\n",
        "    print(\"\\n\\nğŸ“‘ CHAPTER MARKERS:\")\n",
        "    print(\"=\"*60)\n",
        "    print(results['chapters'])\n",
        "    print(\"=\"*60)\n",
        "\n",
        "# Save to file\n",
        "with open('summary_output.txt', 'w') as f:\n",
        "    f.write(\"VIDEO SUMMARY\\n\")\n",
        "    f.write(\"=\"*60 + \"\\n\\n\")\n",
        "    f.write(results['summary'])\n",
        "    f.write(\"\\n\\n\" + \"=\"*60 + \"\\n\\n\")\n",
        "    f.write(\"CHAPTER MARKERS\\n\")\n",
        "    f.write(\"=\"*60 + \"\\n\\n\")\n",
        "    f.write(results['chapters'])\n",
        "\n",
        "print(\"\\n\\nğŸ’¾ Summary saved to: summary_output.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23GeaPD696E9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a5daee28-d5fc-4790-b57b-372827f0da57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting chromadb\n",
            "  Downloading chromadb-1.3.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.3.0)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.12/dist-packages (from chromadb) (2.11.10)\n",
            "Collecting pybase64>=1.4.1 (from chromadb)\n",
            "  Downloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.38.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.12/dist-packages (from chromadb) (2.0.2)\n",
            "Collecting posthog<6.0.0,>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.15.0)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.38.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.22.1)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.76.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.20.0)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-34.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (8.5.0)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.0.3)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb) (3.11.4)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.25.1)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (25.0)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.28.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.4)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Collecting urllib3<2.4.0,>=1.24.2 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.9.23)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.3)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.71.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.38.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.38.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.38.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.38.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_sdk-1.38.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_api-1.38.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.59b0 (from opentelemetry-sdk>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (0.4.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers>=0.13.2->chromadb) (0.36.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (8.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (1.2.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb) (3.3.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Downloading chromadb-1.3.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m20.8/20.8 MB\u001b[0m \u001b[31m125.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl (278 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-34.1.0-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m103.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (103 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m133.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.38.0-py3-none-any.whl (19 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.38.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.38.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_sdk-1.38.0-py3-none-any.whl (132 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m132.3/132.3 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.38.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m65.9/65.9 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m208.0/208.0 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
            "Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (517 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (4.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m143.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (456 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m456.8/456.8 kB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=5775519b6fdc9b9af3312d8ef8671f60cdd9e7280afac1ee3ee41926ccb08c3e\n",
            "  Stored in directory: /root/.cache/pip/wheels/d5/3d/69/8d68d249cd3de2584f226e27fd431d6344f7d70fd856ebd01b\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, durationpy, uvloop, urllib3, pybase64, opentelemetry-proto, mmh3, humanfriendly, httptools, bcrypt, backoff, watchfiles, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, posthog, opentelemetry-semantic-conventions, onnxruntime, opentelemetry-sdk, kubernetes, opentelemetry-exporter-otlp-proto-grpc, chromadb\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.5.0\n",
            "    Uninstalling urllib3-2.5.0:\n",
            "      Successfully uninstalled urllib3-2.5.0\n",
            "  Attempting uninstall: opentelemetry-proto\n",
            "    Found existing installation: opentelemetry-proto 1.37.0\n",
            "    Uninstalling opentelemetry-proto-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-proto-1.37.0\n",
            "  Attempting uninstall: opentelemetry-exporter-otlp-proto-common\n",
            "    Found existing installation: opentelemetry-exporter-otlp-proto-common 1.37.0\n",
            "    Uninstalling opentelemetry-exporter-otlp-proto-common-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-exporter-otlp-proto-common-1.37.0\n",
            "  Attempting uninstall: opentelemetry-api\n",
            "    Found existing installation: opentelemetry-api 1.37.0\n",
            "    Uninstalling opentelemetry-api-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-api-1.37.0\n",
            "  Attempting uninstall: opentelemetry-semantic-conventions\n",
            "    Found existing installation: opentelemetry-semantic-conventions 0.58b0\n",
            "    Uninstalling opentelemetry-semantic-conventions-0.58b0:\n",
            "      Successfully uninstalled opentelemetry-semantic-conventions-0.58b0\n",
            "  Attempting uninstall: opentelemetry-sdk\n",
            "    Found existing installation: opentelemetry-sdk 1.37.0\n",
            "    Uninstalling opentelemetry-sdk-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-sdk-1.37.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-adk 1.17.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.38.0 which is incompatible.\n",
            "google-adk 1.17.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-exporter-otlp-proto-common==1.37.0, but you have opentelemetry-exporter-otlp-proto-common 1.38.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.38.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-sdk~=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed backoff-2.2.1 bcrypt-5.0.0 chromadb-1.3.0 coloredlogs-15.0.1 durationpy-0.10 httptools-0.7.1 humanfriendly-10.0 kubernetes-34.1.0 mmh3-5.2.0 onnxruntime-1.23.2 opentelemetry-api-1.38.0 opentelemetry-exporter-otlp-proto-common-1.38.0 opentelemetry-exporter-otlp-proto-grpc-1.38.0 opentelemetry-proto-1.38.0 opentelemetry-sdk-1.38.0 opentelemetry-semantic-conventions-0.59b0 posthog-5.4.0 pybase64-1.4.2 pypika-0.48.9 urllib3-2.3.0 uvloop-0.22.1 watchfiles-1.1.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "urllib3"
                ]
              },
              "id": "80dbb49b291d403b9f8dbc55742726da"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… ChromaDB installed successfully!\n"
          ]
        }
      ],
      "source": [
        "# Install ChromaDB with proper dependency handling\n",
        "# !pip install --upgrade pip setuptools wheel\n",
        "!pip install jedi>=0.16  # Fix the missing dependency\n",
        "!pip install chromadb\n",
        "\n",
        "print(\"âœ… ChromaDB installed successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXvps7T--kjv",
        "outputId": "c1143d03-147e-42c7-a87c-5a5b8677b2f3",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ†“ Using free SentenceTransformer embeddings (all-MiniLM-L6-v2)\n",
            "âœ… Embedding Agent initialized with sentence_transformer\n",
            "âœ… Vector database created: video_transcripts\n",
            "\n",
            "ğŸ¯ Enhanced Embedding Agent ready! (Using free embeddings)\n"
          ]
        }
      ],
      "source": [
        "#@title Embedding Agent\n",
        "import chromadb\n",
        "from chromadb.utils import embedding_functions\n",
        "import google.generativeai as genai\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "from typing import List, Dict, Any, Optional\n",
        "import logging\n",
        "\n",
        "class EnhancedEmbeddingAgent:\n",
        "    def __init__(self, embedding_model: str = \"sentence_transformer\", gemini_api_key: Optional[str] = None):\n",
        "        \"\"\"\n",
        "        Initialize Embedding Agent with multiple embedding options\n",
        "\n",
        "        Args:\n",
        "            embedding_model: \"sentence_transformer\" (free), \"gemini\" (paid), or \"openai\" (paid)\n",
        "            gemini_api_key: Optional API key for Gemini (only needed if using Gemini)\n",
        "        \"\"\"\n",
        "        self.embedding_model = embedding_model\n",
        "        self.chroma_client = chromadb.Client()\n",
        "\n",
        "        # Clean up existing collection\n",
        "        try:\n",
        "            self.chroma_client.delete_collection(\"video_transcripts\")\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        # Initialize embedding function based on choice\n",
        "        if embedding_model == \"sentence_transformer\":\n",
        "            print(\"ğŸ†“ Using free SentenceTransformer embeddings (all-MiniLM-L6-v2)\")\n",
        "            self.embedding_function = embedding_functions.SentenceTransformerEmbeddingFunction(\n",
        "                model_name=\"all-MiniLM-L6-v2\"\n",
        "            )\n",
        "        elif embedding_model == \"gemini\" and gemini_api_key:\n",
        "            print(\"ğŸ”‘ Using Gemini embeddings (paid)\")\n",
        "            genai.configure(api_key=gemini_api_key)\n",
        "            self.embedding_function = self._gemini_embedding_function\n",
        "        elif embedding_model == \"openai\":\n",
        "            print(\"ğŸ”‘ Using OpenAI embeddings (paid)\")\n",
        "            # You would need to install openai package and set API key\n",
        "            # self.embedding_function = embedding_functions.OpenAIEmbeddingFunction(...)\n",
        "            raise NotImplementedError(\"OpenAI embeddings not implemented in this example\")\n",
        "        else:\n",
        "            print(\"ğŸ†“ Defaulting to free SentenceTransformer embeddings\")\n",
        "            self.embedding_function = embedding_functions.SentenceTransformerEmbeddingFunction(\n",
        "                model_name=\"all-MiniLM-L6-v2\"\n",
        "            )\n",
        "\n",
        "        # Create collection\n",
        "        self.collection = self.chroma_client.create_collection(\n",
        "            name=\"video_transcripts\",\n",
        "            embedding_function=self.embedding_function\n",
        "        )\n",
        "\n",
        "        # Initialize SentenceTransformer for manual embeddings if needed\n",
        "        self.sentence_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "        print(f\"âœ… Embedding Agent initialized with {embedding_model}\")\n",
        "        print(f\"âœ… Vector database created: {self.collection.name}\")\n",
        "\n",
        "    def _gemini_embedding_function(self, texts: List[str]) -> List[List[float]]:\n",
        "        \"\"\"Custom embedding function for Gemini\"\"\"\n",
        "        try:\n",
        "            embeddings = []\n",
        "            for text in texts:\n",
        "                # Gemini embedding API call\n",
        "                result = genai.embed_content(\n",
        "                    model=\"models/embedding-001\",\n",
        "                    content=text,\n",
        "                    task_type=\"retrieval_document\"\n",
        "                )\n",
        "                embeddings.append(result['embedding'])\n",
        "            return embeddings\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Gemini embedding failed: {e}\")\n",
        "            # Fallback to SentenceTransformer\n",
        "            print(\"ğŸ”„ Falling back to SentenceTransformer embeddings\")\n",
        "            return self.sentence_model.encode(texts).tolist()\n",
        "\n",
        "    def chunk_transcript(self, transcript_text: str, chunk_size: int = 500, overlap: int = 50) -> List[str]:\n",
        "        \"\"\"Split transcript into overlapping chunks with smart paragraph boundaries\"\"\"\n",
        "        words = transcript_text.split()\n",
        "        chunks = []\n",
        "\n",
        "        # If transcript is short, return as single chunk\n",
        "        if len(words) <= chunk_size:\n",
        "            return [transcript_text]\n",
        "\n",
        "        # Smart chunking with sentence/paragraph awareness\n",
        "        sentences = transcript_text.split('. ')\n",
        "        current_chunk = []\n",
        "        current_length = 0\n",
        "\n",
        "        for sentence in sentences:\n",
        "            sentence_words = sentence.split()\n",
        "            sentence_length = len(sentence_words)\n",
        "\n",
        "            # If adding this sentence exceeds chunk size, save current chunk\n",
        "            if current_length + sentence_length > chunk_size and current_chunk:\n",
        "                chunks.append(' '.join(current_chunk))\n",
        "                # Start new chunk with overlap\n",
        "                overlap_words = current_chunk[-overlap:] if len(current_chunk) > overlap else current_chunk\n",
        "                current_chunk = overlap_words\n",
        "                current_length = len(overlap_words)\n",
        "\n",
        "            current_chunk.extend(sentence_words)\n",
        "            current_length += sentence_length\n",
        "\n",
        "        # Add final chunk\n",
        "        if current_chunk:\n",
        "            chunks.append(' '.join(current_chunk))\n",
        "\n",
        "        print(f\"âœ‚ï¸  Created {len(chunks)} chunks from transcript\")\n",
        "        return chunks\n",
        "\n",
        "    def store_embeddings(self, transcript_text: str, metadata: Dict[str, Any] = None) -> Dict[str, Any]:\n",
        "        \"\"\"Chunk transcript and store embeddings in vector DB\"\"\"\n",
        "        try:\n",
        "            print(\"\\n\" + \"=\"*50)\n",
        "            print(\"ğŸ¤– ENHANCED EMBEDDING AGENT STARTED\")\n",
        "            print(\"=\"*50)\n",
        "\n",
        "            print(\"âœ‚ï¸  Chunking transcript with smart boundaries...\")\n",
        "            chunks = self.chunk_transcript(transcript_text)\n",
        "\n",
        "            if not chunks:\n",
        "                print(\"âŒ No chunks created from transcript\")\n",
        "                return None\n",
        "\n",
        "            print(f\"âœ… Created {len(chunks)} chunks\")\n",
        "            print(f\"ğŸ“Š Chunk sizes: {[len(chunk.split()) for chunk in chunks]} words\")\n",
        "\n",
        "            print(\"\\nğŸ§  Generating embeddings...\")\n",
        "\n",
        "            # Prepare metadata for each chunk\n",
        "            base_metadata = metadata or {}\n",
        "            metadatas = []\n",
        "            for i, chunk in enumerate(chunks):\n",
        "                chunk_metadata = base_metadata.copy()\n",
        "                chunk_metadata.update({\n",
        "                    \"chunk_index\": i,\n",
        "                    \"chunk_length\": len(chunk),\n",
        "                    \"word_count\": len(chunk.split()),\n",
        "                    \"embedding_model\": self.embedding_model\n",
        "                })\n",
        "                metadatas.append(chunk_metadata)\n",
        "\n",
        "            # Add to ChromaDB collection\n",
        "            ids = [f\"chunk_{i}_{hash(chunk) % 10000}\" for i, chunk in enumerate(chunks)]\n",
        "\n",
        "            self.collection.add(\n",
        "                documents=chunks,\n",
        "                ids=ids,\n",
        "                metadatas=metadatas\n",
        "            )\n",
        "\n",
        "            # Verify storage\n",
        "            collection_count = self.collection.count()\n",
        "            print(f\"âœ… Stored {collection_count} chunks in vector database\")\n",
        "\n",
        "            stats = {\n",
        "                'total_chunks': len(chunks),\n",
        "                'collection_name': self.collection.name,\n",
        "                'embedding_model': self.embedding_model,\n",
        "                'average_chunk_size': np.mean([len(chunk.split()) for chunk in chunks])\n",
        "            }\n",
        "\n",
        "            print(f\"ğŸ“Š Embedding Stats: {stats}\")\n",
        "            print(\"=\"*50)\n",
        "\n",
        "            return stats\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Embedding storage error: {e}\")\n",
        "            logging.error(f\"Embedding storage failed: {e}\")\n",
        "            return None\n",
        "\n",
        "    def semantic_search(self, query: str, n_results: int = 3, filter_metadata: Optional[Dict] = None) -> Dict[str, Any]:\n",
        "        \"\"\"Enhanced semantic search with filtering\"\"\"\n",
        "        try:\n",
        "            print(f\"ğŸ” Performing semantic search: '{query}'\")\n",
        "\n",
        "            results = self.collection.query(\n",
        "                query_texts=[query],\n",
        "                n_results=n_results,\n",
        "                where=filter_metadata  # Optional metadata filtering\n",
        "            )\n",
        "\n",
        "            if results and results['documents']:\n",
        "                print(f\"âœ… Found {len(results['documents'][0])} relevant results\")\n",
        "                return {\n",
        "                    'documents': results['documents'][0],\n",
        "                    'metadatas': results['metadatas'][0],\n",
        "                    'distances': results['distances'][0],\n",
        "                    'query': query\n",
        "                }\n",
        "            else:\n",
        "                print(\"âŒ No results found\")\n",
        "                return None\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Semantic search error: {e}\")\n",
        "            return None\n",
        "\n",
        "    def get_collection_stats(self) -> Dict[str, Any]:\n",
        "        \"\"\"Get statistics about the vector database\"\"\"\n",
        "        try:\n",
        "            count = self.collection.count()\n",
        "            # Get sample of documents to analyze\n",
        "            sample_results = self.collection.get(limit=min(10, count))\n",
        "\n",
        "            stats = {\n",
        "                'total_documents': count,\n",
        "                'embedding_model': self.embedding_model,\n",
        "                'sample_chunk_sizes': [len(doc.split()) for doc in sample_results['documents']] if sample_results['documents'] else []\n",
        "            }\n",
        "\n",
        "            return stats\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Error getting collection stats: {e}\")\n",
        "            return {}\n",
        "\n",
        "    def clear_database(self):\n",
        "        \"\"\"Clear the vector database\"\"\"\n",
        "        try:\n",
        "            self.chroma_client.delete_collection(\"video_transcripts\")\n",
        "            self.collection = self.chroma_client.create_collection(\n",
        "                name=\"video_transcripts\",\n",
        "                embedding_function=self.embedding_function\n",
        "            )\n",
        "            print(\"âœ… Vector database cleared\")\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Error clearing database: {e}\")\n",
        "\n",
        "# Initialize with free embeddings by default\n",
        "embedding_agent = EnhancedEmbeddingAgent(embedding_model=\"sentence_transformer\")\n",
        "print(\"\\nğŸ¯ Enhanced Embedding Agent ready! (Using free embeddings)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2A-1YGHCaY0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "0367bfab-8990-49ac-cf58-808936ec137f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§ª Testing Embedding Agent...\n",
            "âŒ transcript.txt file not found. Please run the transcription agent first.\n"
          ]
        }
      ],
      "source": [
        "#@title Test the Embedding Agent\n",
        "print(\"ğŸ§ª Testing Embedding Agent...\")\n",
        "\n",
        "# Read the transcript file\n",
        "try:\n",
        "    with open('transcript.txt', 'r') as f:\n",
        "        transcript = f.read()\n",
        "    print(f\"ğŸ“– Loaded transcript: {len(transcript)} characters\")\n",
        "\n",
        "    # Store embeddings\n",
        "    result = embedding_agent.store_embeddings(transcript)\n",
        "\n",
        "    if result:\n",
        "        print(f\"ğŸ“Š Embedding Stats:\")\n",
        "        print(f\"   Total chunks: {result['total_chunks']}\")\n",
        "        print(f\"   Collection: {result['collection_name']}\")\n",
        "\n",
        "        # Test search functionality\n",
        "        print(\"\\nğŸ” Testing search functionality...\")\n",
        "        test_query = \"main topic of the video\"\n",
        "        search_results = embedding_agent.search_similar(test_query, n_results=2)\n",
        "\n",
        "        if search_results:\n",
        "            print(f\"âœ… Search test successful!\")\n",
        "            print(f\"   Query: '{test_query}'\")\n",
        "            print(f\"   Found {len(search_results['documents'][0])} results\")\n",
        "        else:\n",
        "            print(\"âŒ Search test failed\")\n",
        "\n",
        "        print(f\"\\nâœ… Vector database is ready for Q&A!\")\n",
        "    else:\n",
        "        print(\"âŒ Failed to store embeddings\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"âŒ transcript.txt file not found. Please run the transcription agent first.\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Testing error: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTeSkv9CCjBQ",
        "outputId": "07e05af7-e256-4ad1-d4c8-49b75082a81c",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Q&A Agent initialized\n",
            "\n",
            "ğŸ¯ Q&A Agent ready to use!\n"
          ]
        }
      ],
      "source": [
        "#@title AGENT 4: Q&A Agent (uses RAG) - FIXED VERSION\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "class QAAgent:\n",
        "    def __init__(self, embedding_agent):\n",
        "        \"\"\"Initialize Q&A Agent with Gemini and access to vector DB\"\"\"\n",
        "        # Get API key from Colab secrets\n",
        "        gemini_api_key = userdata.get('GOOGLE_API_KEY')\n",
        "        genai.configure(api_key=gemini_api_key)\n",
        "        self.model = genai.GenerativeModel('models/gemini-2.0-flash')\n",
        "        self.embedding_agent = embedding_agent\n",
        "        print(\"âœ… Q&A Agent initialized\")\n",
        "\n",
        "    def answer_question(self, question):\n",
        "        \"\"\"Answer a question using RAG (Retrieval Augmented Generation)\"\"\"\n",
        "        try:\n",
        "            print(\"\\n\" + \"=\"*50)\n",
        "            print(\"ğŸ¤– Q&A AGENT STARTED\")\n",
        "            print(\"=\"*50 + \"\\n\")\n",
        "\n",
        "            print(f\"â“ Question: {question}\\n\")\n",
        "\n",
        "            # Step 1: Search vector DB for relevant context\n",
        "            print(\"ğŸ” Searching vector database for relevant content...\")\n",
        "\n",
        "            # Use the semantic_search method that exists in your embedding agent\n",
        "            search_results = self.embedding_agent.semantic_search(question, n_results=3)\n",
        "\n",
        "            print(f\"ğŸ“Š Search results type: {type(search_results)}\")\n",
        "\n",
        "            if not search_results or not search_results.get('documents'):\n",
        "                print(\"âŒ No documents found in search results\")\n",
        "                print(f\"ğŸ” Search results: {search_results}\")\n",
        "                return \"I couldn't find relevant information in the video to answer this question.\"\n",
        "\n",
        "            # Get relevant chunks - handle the response format\n",
        "            relevant_chunks = search_results['documents']\n",
        "            context = \"\\n\\n\".join(relevant_chunks)\n",
        "\n",
        "            print(f\"âœ… Found {len(relevant_chunks)} relevant sections\")\n",
        "            print(f\"ğŸ“ First chunk preview: {relevant_chunks[0][:200]}...\\n\")\n",
        "\n",
        "            # Step 2: Generate answer using context\n",
        "            print(\"ğŸ’­ Generating answer using context...\")\n",
        "\n",
        "            prompt = f\"\"\"\n",
        "            Based on the following content from a video transcript, answer the user's question.\n",
        "\n",
        "            Context from video:\n",
        "            {context}\n",
        "\n",
        "            User's question: {question}\n",
        "\n",
        "            Instructions:\n",
        "            - Answer directly and concisely\n",
        "            - If the user is asking questions abount the video and not the content in the video, then use your knowledge and answer him. In this case, dont say Idk\n",
        "            - Use only information from the provided context to answer questions related to it.\n",
        "            - If the context doesn't contain what user is asking, say \"I cannot find this information in the video\"\n",
        "            - Be helpful and clear\n",
        "            - Interact with the user in a friendly way\n",
        "            - You can use emojis and images to make the user understand better\n",
        "\n",
        "            Answer:\n",
        "            \"\"\"\n",
        "\n",
        "            response = self.model.generate_content(prompt)\n",
        "            answer = response.text\n",
        "\n",
        "            print(\"âœ… Answer generated!\")\n",
        "            print(f\"ğŸ¤– Answer: {answer}\\n\")\n",
        "            print(\"=\"*50)\n",
        "\n",
        "            return {\n",
        "                'question': question,\n",
        "                'answer': answer,\n",
        "                'sources': relevant_chunks\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Q&A error: {e}\")\n",
        "            import traceback\n",
        "            print(f\"ğŸ” Full traceback: {traceback.format_exc()}\")\n",
        "            return None\n",
        "\n",
        "# Re-initialize the Q&A Agent with the correct method\n",
        "qa_agent = QAAgent(embedding_agent)\n",
        "print(\"\\nğŸ¯ Q&A Agent ready to use!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLdyKI03DYXp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "outputId": "f2f0250f-755f-40f6-da74-298e90b03b4c",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§ª Testing Q&A Agent with sample questions:\n",
            "\n",
            "\n",
            "==================================================\n",
            "ğŸ¤– Q&A AGENT STARTED\n",
            "==================================================\n",
            "\n",
            "â“ Question: What is the main topic of this video?\n",
            "\n",
            "ğŸ” Searching vector database for relevant content...\n",
            "ğŸ” Performing semantic search: 'What is the main topic of this video?'\n",
            "âœ… Found 3 relevant results\n",
            "ğŸ“Š Search results type: <class 'dict'>\n",
            "âœ… Found 3 relevant sections\n",
            "ğŸ“ First chunk preview: Alright, let's learn some trigonometry or Algebra three Or Precalculus Okay, lesson number one These are all the same thing Trigonometry is algebra three, trig meaning three, and onometry, meaning the...\n",
            "\n",
            "ğŸ’­ Generating answer using context...\n",
            "âœ… Answer generated!\n",
            "ğŸ¤– Answer: The main topic of this video is trigonometry, specifically focusing on the unit circle and trigonometric functions like sine, cosine, and tangent.\n",
            "\n",
            "\n",
            "==================================================\n",
            "\n",
            "ğŸ’¬ ANSWER:\n",
            "------------------------------------------------------------\n",
            "The main topic of this video is trigonometry, specifically focusing on the unit circle and trigonometric functions like sine, cosine, and tangent.\n",
            "\n",
            "------------------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1375935716.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# Small delay between questions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nâœ… Q&A Agent testing complete!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#@title Test the Q&A Agent with sample questions\n",
        "\n",
        "# You can modify these questions based on your video content\n",
        "test_questions = [\n",
        "    \"What is the main topic of this video?\",\n",
        "    \"What are the key points discussed?\",\n",
        "    \"Can you summarize what was said?\"\n",
        "]\n",
        "\n",
        "print(\"ğŸ§ª Testing Q&A Agent with sample questions:\\n\")\n",
        "\n",
        "for question in test_questions:\n",
        "    result = qa_agent.answer_question(question)\n",
        "\n",
        "    if result:\n",
        "        print(f\"\\nğŸ’¬ ANSWER:\")\n",
        "        print(\"-\" * 60)\n",
        "        print(result['answer'])\n",
        "        print(\"-\" * 60)\n",
        "        print()\n",
        "\n",
        "    # Small delay between questions\n",
        "    import time\n",
        "    time.sleep(2)\n",
        "\n",
        "print(\"\\nâœ… Q&A Agent testing complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24vZGLSZEByx",
        "outputId": "fa803060-71fa-42be-cf7b-c7593d94a36b",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Frame Extractor initialized\n",
            "\n",
            "ğŸ¯ Frame Extractor ready to use!\n"
          ]
        }
      ],
      "source": [
        "#@title Frame Extraction\n",
        "import cv2\n",
        "from moviepy.editor import VideoFileClip\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image, display\n",
        "import os\n",
        "import base64\n",
        "from PIL import Image as PILImage\n",
        "\n",
        "class FrameExtractor:\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize Frame Extractor\"\"\"\n",
        "        print(\"âœ… Frame Extractor initialized\")\n",
        "\n",
        "    def extract_key_frames(self, video_path, num_frames=5):\n",
        "        \"\"\"Extract key frames from video at regular intervals\"\"\"\n",
        "        try:\n",
        "            print(\"\\n\" + \"=\"*50)\n",
        "            print(\"ğŸ¬ FRAME EXTRACTION STARTED\")\n",
        "            print(\"=\"*50 + \"\\n\")\n",
        "\n",
        "            print(f\"ğŸ“¹ Processing video: {video_path}\")\n",
        "\n",
        "            # Get video info\n",
        "            video = VideoFileClip(video_path)\n",
        "            duration = video.duration\n",
        "            fps = video.fps\n",
        "            total_frames = int(duration * fps)\n",
        "\n",
        "            print(f\"   Duration: {duration:.1f} seconds\")\n",
        "            print(f\"   FPS: {fps}\")\n",
        "            print(f\"   Total frames: {total_frames}\\n\")\n",
        "\n",
        "            # Calculate frame intervals\n",
        "            interval = duration / (num_frames + 1)\n",
        "            timestamps = [interval * (i + 1) for i in range(num_frames)]\n",
        "\n",
        "            print(f\"ğŸï¸  Extracting {num_frames} key frames...\")\n",
        "\n",
        "            # Create frames directory\n",
        "            os.makedirs('extracted_frames', exist_ok=True)\n",
        "\n",
        "            frames_data = []\n",
        "\n",
        "            for idx, timestamp in enumerate(timestamps):\n",
        "                # Extract frame at timestamp\n",
        "                frame = video.get_frame(timestamp)\n",
        "\n",
        "                # Save frame\n",
        "                frame_path = f'extracted_frames/frame_{idx+1}_at_{timestamp:.1f}s.jpg'\n",
        "                plt.imsave(frame_path, frame)\n",
        "\n",
        "                frames_data.append({\n",
        "                    'frame_number': idx + 1,\n",
        "                    'timestamp': timestamp,\n",
        "                    'path': frame_path\n",
        "                })\n",
        "\n",
        "                print(f\"   âœ“ Frame {idx+1} at {timestamp:.1f}s\")\n",
        "\n",
        "            video.close()\n",
        "\n",
        "            print(f\"\\nâœ… Extracted {len(frames_data)} frames\")\n",
        "            print(\"=\"*50 + \"\\n\")\n",
        "\n",
        "            return frames_data\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Frame extraction error: {e}\")\n",
        "            return None\n",
        "\n",
        "    def display_frames(self, frames_data):\n",
        "        \"\"\"Display extracted frames\"\"\"\n",
        "        print(\"ğŸ–¼ï¸  EXTRACTED FRAMES:\\n\")\n",
        "\n",
        "        for frame_info in frames_data:\n",
        "            print(f\"Frame {frame_info['frame_number']} (at {frame_info['timestamp']:.1f}s):\")\n",
        "            display(Image(filename=frame_info['path'], width=400))\n",
        "            print()\n",
        "\n",
        "# Initialize Frame Extractor\n",
        "frame_extractor = FrameExtractor()\n",
        "print(\"\\nğŸ¯ Frame Extractor ready to use!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "E7wbUT1cXBBe",
        "outputId": "7bba547e-962a-4865-8f71-90681c302da9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Video Content Analyzer System Ready!\n",
            "ğŸš€ Launching Gradio Interface...\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://b8f755e56b0d1f440b.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://b8f755e56b0d1f440b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "ğŸ¤– TRANSCRIPTION AGENT STARTED\n",
            "==================================================\n",
            "\n",
            "ğŸ¬ Extracting audio from: /tmp/gradio/2ba17ff7c4873ce113d539bab9f36197d7501f98b018417a01805fdf6bf2dc71/All of Trigonometry Explained in 5 Minutes fDjLmYlweUA.webm\n",
            "âœ… Audio extracted: extracted_audio.mp3\n",
            "ğŸ¤ Transcribing audio... (this may take a minute)\n",
            "âœ… Transcription complete!\n",
            "\n",
            "ğŸ“Š Transcription Stats:\n",
            "   Duration: 0.3 seconds\n",
            "   Words: 1041\n",
            "   Characters: 5412\n",
            "\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "ğŸ¤– SUMMARY AGENT STARTED\n",
            "==================================================\n",
            "\n",
            "ğŸ“ Analyzing transcript and generating summary...\n",
            "âœ… Summary generated successfully!\n",
            "\n",
            "==================================================\n",
            "\n",
            "ğŸ“Œ Generating chapter markers...\n",
            "âœ… Chapter markers generated!\n",
            "\n",
            "\n",
            "==================================================\n",
            "ğŸ¤– ENHANCED EMBEDDING AGENT STARTED\n",
            "==================================================\n",
            "âœ‚ï¸  Chunking transcript with smart boundaries...\n",
            "âœ‚ï¸  Created 3 chunks from transcript\n",
            "âœ… Created 3 chunks\n",
            "ğŸ“Š Chunk sizes: [494, 487, 160] words\n",
            "\n",
            "ğŸ§  Generating embeddings...\n",
            "âœ… Stored 3 chunks in vector database\n",
            "ğŸ“Š Embedding Stats: {'total_chunks': 3, 'collection_name': 'video_transcripts', 'embedding_model': 'sentence_transformer', 'average_chunk_size': np.float64(380.3333333333333)}\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "ğŸ¬ FRAME EXTRACTION STARTED\n",
            "==================================================\n",
            "\n",
            "ğŸ“¹ Processing video: /tmp/gradio/2ba17ff7c4873ce113d539bab9f36197d7501f98b018417a01805fdf6bf2dc71/All of Trigonometry Explained in 5 Minutes fDjLmYlweUA.webm\n",
            "   Duration: 299.8 seconds\n",
            "   FPS: 30.0\n",
            "   Total frames: 8993\n",
            "\n",
            "ğŸï¸  Extracting 5 key frames...\n",
            "   âœ“ Frame 1 at 50.0s\n",
            "   âœ“ Frame 2 at 99.9s\n",
            "   âœ“ Frame 3 at 149.9s\n",
            "   âœ“ Frame 4 at 199.9s\n",
            "   âœ“ Frame 5 at 249.8s\n",
            "\n",
            "âœ… Extracted 5 frames\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "ğŸ¤– TRANSCRIPTION AGENT STARTED\n",
            "==================================================\n",
            "\n",
            "ğŸ¬ Extracting audio from: /tmp/gradio/2ba17ff7c4873ce113d539bab9f36197d7501f98b018417a01805fdf6bf2dc71/All of Trigonometry Explained in 5 Minutes fDjLmYlweUA.webm\n",
            "âœ… Audio extracted: extracted_audio.mp3\n",
            "ğŸ¤ Transcribing audio... (this may take a minute)\n",
            "âœ… Transcription complete!\n",
            "\n",
            "ğŸ“Š Transcription Stats:\n",
            "   Duration: 0.3 seconds\n",
            "   Words: 1041\n",
            "   Characters: 5412\n",
            "\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "ğŸ¤– SUMMARY AGENT STARTED\n",
            "==================================================\n",
            "\n",
            "ğŸ“ Analyzing transcript and generating summary...\n",
            "âœ… Summary generated successfully!\n",
            "\n",
            "==================================================\n",
            "\n",
            "ğŸ“Œ Generating chapter markers...\n",
            "âœ… Chapter markers generated!\n",
            "\n",
            "\n",
            "==================================================\n",
            "ğŸ¤– ENHANCED EMBEDDING AGENT STARTED\n",
            "==================================================\n",
            "âœ‚ï¸  Chunking transcript with smart boundaries...\n",
            "âœ‚ï¸  Created 3 chunks from transcript\n",
            "âœ… Created 3 chunks\n",
            "ğŸ“Š Chunk sizes: [494, 487, 160] words\n",
            "\n",
            "ğŸ§  Generating embeddings...\n",
            "âœ… Stored 3 chunks in vector database\n",
            "ğŸ“Š Embedding Stats: {'total_chunks': 3, 'collection_name': 'video_transcripts', 'embedding_model': 'sentence_transformer', 'average_chunk_size': np.float64(380.3333333333333)}\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "ğŸ¬ FRAME EXTRACTION STARTED\n",
            "==================================================\n",
            "\n",
            "ğŸ“¹ Processing video: /tmp/gradio/2ba17ff7c4873ce113d539bab9f36197d7501f98b018417a01805fdf6bf2dc71/All of Trigonometry Explained in 5 Minutes fDjLmYlweUA.webm\n",
            "   Duration: 299.8 seconds\n",
            "   FPS: 30.0\n",
            "   Total frames: 8993\n",
            "\n",
            "ğŸï¸  Extracting 5 key frames...\n",
            "   âœ“ Frame 1 at 50.0s\n",
            "   âœ“ Frame 2 at 99.9s\n",
            "   âœ“ Frame 3 at 149.9s\n",
            "   âœ“ Frame 4 at 199.9s\n",
            "   âœ“ Frame 5 at 249.8s\n",
            "\n",
            "âœ… Extracted 5 frames\n",
            "==================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:    Exception in ASGI application\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/protocols/http/httptools_impl.py\", line 409, in run_asgi\n",
            "    result = await app(  # type: ignore[func-returns-value]\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/applications.py\", line 1134, in __call__\n",
            "    await super().__call__(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/applications.py\", line 113, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/errors.py\", line 186, in __call__\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/errors.py\", line 164, in __call__\n",
            "    await self.app(scope, receive, _send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/brotli_middleware.py\", line 74, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 888, in __call__\n",
            "    await self.simple_response(scope, receive, send, request_headers=headers)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 904, in simple_response\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/exceptions.py\", line 63, in __call__\n",
            "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/middleware/asyncexitstack.py\", line 18, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 716, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 736, in app\n",
            "    await route.handle(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 290, in handle\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 124, in app\n",
            "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 110, in app\n",
            "    response = await f(request)\n",
            "               ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 390, in app\n",
            "    raw_response = await run_endpoint_function(\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 289, in run_endpoint_function\n",
            "    return await dependant.call(**values)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/routes.py\", line 1708, in upload_file\n",
            "    form = await multipart_parser.parse()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 742, in parse\n",
            "    async for chunk in self.stream:\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/requests.py\", line 236, in stream\n",
            "    raise ClientDisconnect()\n",
            "starlette.requests.ClientDisconnect\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://b8f755e56b0d1f440b.gradio.live\n"
          ]
        }
      ],
      "source": [
        "#@title Complete Gradio Interface (Fixed Frame Display + Download Features)\n",
        "import gradio as gr\n",
        "import base64\n",
        "from PIL import Image\n",
        "import tempfile\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "class VideoContentAnalyzer:\n",
        "    def __init__(self, transcription_agent, summary_agent, embedding_agent, qa_agent, frame_extractor):\n",
        "        self.transcription_agent = transcription_agent\n",
        "        self.summary_agent = summary_agent\n",
        "        self.embedding_agent = embedding_agent\n",
        "        self.qa_agent = qa_agent\n",
        "        self.frame_extractor = frame_extractor\n",
        "        self.current_transcript = None\n",
        "        self.current_frames = None\n",
        "        self.current_summary = None\n",
        "\n",
        "    def image_to_base64(self, image_path):\n",
        "        \"\"\"Convert image to base64 for HTML display\"\"\"\n",
        "        try:\n",
        "            with open(image_path, \"rb\") as img_file:\n",
        "                return base64.b64encode(img_file.read()).decode('utf-8')\n",
        "        except Exception as e:\n",
        "            print(f\"Error converting image to base64: {e}\")\n",
        "            return \"\"\n",
        "\n",
        "    def create_text_file(self, content, filename):\n",
        "        \"\"\"Create a temporary text file for download\"\"\"\n",
        "        temp_file = tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8')\n",
        "        temp_file.write(content)\n",
        "        temp_file.close()\n",
        "        return temp_file.name\n",
        "\n",
        "    def create_frames_zip(self, frames_data, zip_filename=\"frames.zip\"):\n",
        "        \"\"\"Create a ZIP file containing all extracted frames\"\"\"\n",
        "        try:\n",
        "            temp_zip = tempfile.NamedTemporaryFile(suffix='.zip', delete=False)\n",
        "            temp_zip.close()\n",
        "\n",
        "            with zipfile.ZipFile(temp_zip.name, 'w') as zipf:\n",
        "                for frame in frames_data:\n",
        "                    if os.path.exists(frame['path']):\n",
        "                        # Use descriptive filename in the zip\n",
        "                        frame_filename = f\"frame_{frame['frame_number']}_at_{frame['timestamp']:.1f}s.jpg\"\n",
        "                        zipf.write(frame['path'], frame_filename)\n",
        "\n",
        "            return temp_zip.name\n",
        "        except Exception as e:\n",
        "            print(f\"Error creating frames ZIP: {e}\")\n",
        "            return None\n",
        "\n",
        "    def process_video(self, video_file):\n",
        "        \"\"\"Process uploaded video - all agents work together\"\"\"\n",
        "        if video_file is None:\n",
        "            return \"Please upload a video file!\", \"\", \"\", \"\", gr.DownloadButton(visible=False), gr.DownloadButton(visible=False), gr.DownloadButton(visible=False)\n",
        "\n",
        "        try:\n",
        "            # Initialize download files as None\n",
        "            transcript_file = None\n",
        "            summary_file = None\n",
        "            frames_zip = None\n",
        "\n",
        "            # Step 1: Transcription\n",
        "            status = \"ğŸ¤ Transcribing video...\\n\"\n",
        "            yield status, \"\", \"\", \"\", gr.DownloadButton(visible=False), gr.DownloadButton(visible=False), gr.DownloadButton(visible=False)\n",
        "\n",
        "            transcript_result = self.transcription_agent.process_video(video_file)\n",
        "            if not transcript_result:\n",
        "                yield \"âŒ Transcription failed!\", \"\", \"\", \"\", gr.DownloadButton(visible=False), gr.DownloadButton(visible=False), gr.DownloadButton(visible=False)\n",
        "                return\n",
        "\n",
        "            self.current_transcript = transcript_result['text']\n",
        "            status += f\"âœ… Transcription complete! ({len(transcript_result['words'])} words)\\n\\n\"\n",
        "\n",
        "            # Step 2: Summary\n",
        "            status += \"ğŸ“ Generating summary...\\n\"\n",
        "            yield status, self.current_transcript[:500] + \"...\", \"\", \"\", gr.DownloadButton(visible=False), gr.DownloadButton(visible=False), gr.DownloadButton(visible=False)\n",
        "\n",
        "            summary_result = self.summary_agent.process_transcript(self.current_transcript)\n",
        "            summary_text = f\"{summary_result['summary']}\\n\\n---\\n\\n{summary_result['chapters']}\"\n",
        "            self.current_summary = summary_text\n",
        "            status += \"âœ… Summary generated!\\n\\n\"\n",
        "\n",
        "            # Step 3: Embeddings\n",
        "            status += \"ğŸ§  Creating vector database...\\n\"\n",
        "            yield status, self.current_transcript[:500] + \"...\", summary_text, \"\", gr.DownloadButton(visible=False), gr.DownloadButton(visible=False), gr.DownloadButton(visible=False)\n",
        "\n",
        "            embedding_result = self.embedding_agent.store_embeddings(self.current_transcript)\n",
        "            status += f\"âœ… Vector DB ready! ({embedding_result['total_chunks']} chunks)\\n\\n\"\n",
        "\n",
        "            # Step 4: Frame Extraction\n",
        "            status += \"ğŸ¬ Extracting key frames...\\n\"\n",
        "            yield status, self.current_transcript[:500] + \"...\", summary_text, \"\", gr.DownloadButton(visible=False), gr.DownloadButton(visible=False), gr.DownloadButton(visible=False)\n",
        "\n",
        "            self.current_frames = self.frame_extractor.extract_key_frames(video_file, num_frames=5)\n",
        "\n",
        "            # Create frames display with base64 images\n",
        "            frames_html = \"<div style='display: grid; grid-template-columns: repeat(2, 1fr); gap: 15px; padding: 10px;'>\"\n",
        "            if self.current_frames:\n",
        "                for frame in self.current_frames:\n",
        "                    base64_image = self.image_to_base64(frame['path'])\n",
        "                    if base64_image:\n",
        "                        frames_html += f\"\"\"\n",
        "                        <div style='text-align: center; border: 1px solid #ddd; border-radius: 10px; padding: 10px; background: #f9f9f9;'>\n",
        "                            <img src='data:image/jpeg;base64,{base64_image}' style='width: 100%; max-width: 300px; border-radius: 8px;'>\n",
        "                            <p style='margin: 8px 0; font-weight: bold;'>Frame {frame['frame_number']}</p>\n",
        "                            <p style='margin: 0; color: #666;'>Timestamp: {frame['timestamp']:.1f}s</p>\n",
        "                        </div>\n",
        "                        \"\"\"\n",
        "                    else:\n",
        "                        frames_html += f\"\"\"\n",
        "                        <div style='text-align: center; border: 1px solid #ddd; border-radius: 10px; padding: 10px; background: #f9f9f9;'>\n",
        "                            <p style='color: red;'>Image not found</p>\n",
        "                            <p>Frame {frame['frame_number']} @ {frame['timestamp']:.1f}s</p>\n",
        "                        </div>\n",
        "                        \"\"\"\n",
        "            else:\n",
        "                frames_html += \"<p>No frames extracted</p>\"\n",
        "\n",
        "            frames_html += \"</div>\"\n",
        "\n",
        "            # Create downloadable files\n",
        "            transcript_file = self.create_text_file(self.current_transcript, \"transcript.txt\")\n",
        "            summary_file = self.create_text_file(self.current_summary, \"summary.txt\")\n",
        "            frames_zip = self.create_frames_zip(self.current_frames) if self.current_frames else None\n",
        "\n",
        "            status += \"âœ… Frame extraction complete!\\n\\n\"\n",
        "            status += \"ğŸ‰ All processing complete! You can now ask questions about the video.\"\n",
        "\n",
        "            # Return results with download buttons\n",
        "            yield (\n",
        "                status,\n",
        "                self.current_transcript,\n",
        "                summary_text,\n",
        "                frames_html,\n",
        "                gr.DownloadButton(visible=True, value=transcript_file, label=\"ğŸ“¥ Download Transcript\"),\n",
        "                gr.DownloadButton(visible=True, value=summary_file, label=\"ğŸ“¥ Download Summary\"),\n",
        "                gr.DownloadButton(visible=True, value=frames_zip, label=\"ğŸ“¥ Download Frames\") if frames_zip else gr.DownloadButton(visible=False)\n",
        "            )\n",
        "\n",
        "        except Exception as e:\n",
        "            yield f\"âŒ Error: {str(e)}\", \"\", \"\", \"\", gr.DownloadButton(visible=False), gr.DownloadButton(visible=False), gr.DownloadButton(visible=False)\n",
        "\n",
        "    def answer_question(self, question):\n",
        "        \"\"\"Answer question about the video\"\"\"\n",
        "        if not self.current_transcript:\n",
        "            return \"Please process a video first!\"\n",
        "\n",
        "        if not question or question.strip() == \"\":\n",
        "            return \"Please enter a question!\"\n",
        "\n",
        "        result = self.qa_agent.answer_question(question)\n",
        "\n",
        "        if result:\n",
        "            answer = f\"**Question:** {result['question']}\\n\\n\"\n",
        "            answer += f\"**Answer:** {result['answer']}\\n\\n\"\n",
        "            answer += \"---\\n\\n**Relevant Context:**\\n\\n\"\n",
        "            for i, source in enumerate(result['sources'][:2], 1):\n",
        "                answer += f\"{i}. {source[:200]}...\\n\\n\"\n",
        "            return answer\n",
        "        else:\n",
        "            return \"Sorry, I couldn't generate an answer.\"\n",
        "\n",
        "# Initialize the complete system\n",
        "analyzer = VideoContentAnalyzer(\n",
        "    transcription_agent,\n",
        "    summary_agent,\n",
        "    embedding_agent,\n",
        "    qa_agent,\n",
        "    frame_extractor\n",
        ")\n",
        "\n",
        "print(\"âœ… Video Content Analyzer System Ready!\")\n",
        "\n",
        "# Create Gradio Interface\n",
        "with gr.Blocks(title=\"Video Content Analyzer - Agentic AI\", theme=gr.themes.Soft()) as demo:\n",
        "\n",
        "    gr.Markdown(\"\"\"\n",
        "    # ğŸ¥ Video Content Analyzer - Agentic AI System\n",
        "\n",
        "    Upload a video and let multiple AI agents analyze it for you!\n",
        "\n",
        "    **Features:**\n",
        "    - ğŸ¤ Automatic transcription\n",
        "    - ğŸ“ Intelligent summarization\n",
        "    - ğŸ§  Semantic search with vector database\n",
        "    - ğŸ’¬ Q&A about video content\n",
        "    - ğŸ¬ Key frame extraction\n",
        "    - ğŸ“¥ Download all results\n",
        "    \"\"\")\n",
        "\n",
        "    with gr.Tab(\"ğŸ“¤ Upload & Process Video\"):\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                video_input = gr.Video(label=\"Upload Video File\")\n",
        "                process_btn = gr.Button(\"ğŸš€ Process Video\", variant=\"primary\", size=\"lg\")\n",
        "\n",
        "            with gr.Column():\n",
        "                status_output = gr.Textbox(\n",
        "                    label=\"Processing Status\",\n",
        "                    lines=10,\n",
        "                    max_lines=15\n",
        "                )\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                transcript_output = gr.Textbox(\n",
        "                    label=\"ğŸ“ Transcript\",\n",
        "                    lines=10,\n",
        "                    max_lines=20\n",
        "                )\n",
        "                download_transcript = gr.DownloadButton(\n",
        "                    \"ğŸ“¥ Download Transcript\",\n",
        "                    visible=False,\n",
        "                    variant=\"secondary\"\n",
        "                )\n",
        "\n",
        "            with gr.Column():\n",
        "                summary_output = gr.Textbox(\n",
        "                    label=\"ğŸ“Š Summary & Chapters\",\n",
        "                    lines=10,\n",
        "                    max_lines=20\n",
        "                )\n",
        "                download_summary = gr.DownloadButton(\n",
        "                    \"ğŸ“¥ Download Summary\",\n",
        "                    visible=False,\n",
        "                    variant=\"secondary\"\n",
        "                )\n",
        "\n",
        "        frames_output = gr.HTML(label=\"ğŸ¬ Extracted Key Frames\")\n",
        "\n",
        "        with gr.Row():\n",
        "            download_frames = gr.DownloadButton(\n",
        "                \"ğŸ“¥ Download All Frames (ZIP)\",\n",
        "                visible=False,\n",
        "                variant=\"secondary\"\n",
        "            )\n",
        "\n",
        "    with gr.Tab(\"ğŸ’¬ Ask Questions\"):\n",
        "        gr.Markdown(\"### Ask questions about the video content\")\n",
        "\n",
        "        with gr.Row():\n",
        "            question_input = gr.Textbox(\n",
        "                label=\"Your Question\",\n",
        "                placeholder=\"e.g., What is the main topic discussed?\",\n",
        "                lines=2\n",
        "            )\n",
        "\n",
        "        ask_btn = gr.Button(\"ğŸ” Get Answer\", variant=\"primary\")\n",
        "\n",
        "        answer_output = gr.Markdown(label=\"Answer\")\n",
        "\n",
        "        gr.Markdown(\"\"\"\n",
        "        **Example Questions:**\n",
        "        - What is the main topic of this video?\n",
        "        - What are the key points discussed?\n",
        "        - Can you explain [specific topic] mentioned in the video?\n",
        "        - What conclusions were drawn?\n",
        "        \"\"\")\n",
        "\n",
        "    # Event handlers\n",
        "    process_btn.click(\n",
        "        fn=analyzer.process_video,\n",
        "        inputs=[video_input],\n",
        "        outputs=[\n",
        "            status_output,\n",
        "            transcript_output,\n",
        "            summary_output,\n",
        "            frames_output,\n",
        "            download_transcript,\n",
        "            download_summary,\n",
        "            download_frames\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    ask_btn.click(\n",
        "        fn=analyzer.answer_question,\n",
        "        inputs=[question_input],\n",
        "        outputs=[answer_output]\n",
        "    )\n",
        "\n",
        "# Launch the interface with Colab-friendly settings\n",
        "print(\"ğŸš€ Launching Gradio Interface...\")\n",
        "try:\n",
        "    demo.launch(share=True, debug=True)\n",
        "except Exception as e:\n",
        "    print(f\"Note: If you encounter issues with share=True, try running with share=False\")\n",
        "    demo.launch(share=False, debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In a Colab cell, create .env template\n",
        "env_template = \"\"\"\n",
        "API_KEY=your_api_key_here\n",
        "SECRET_KEY=your_secret_here\n",
        "DATABASE_URL=your_database_url\n",
        "\"\"\"\n",
        "\n",
        "with open('.env.template', 'w') as f:\n",
        "    f.write(env_template)"
      ],
      "metadata": {
        "id": "F6X0Oj9Snb9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This creates your actual .env file with real keys (but DON'T commit this!)\n",
        "real_env = \"\"\"\n",
        "API_KEY=your_actual_secret_key_12345\n",
        "SECRET_KEY=your_actual_secret_67890\n",
        "DATABASE_URL=your_actual_database_url\n",
        "\"\"\"\n",
        "\n",
        "with open('.env', 'w') as f:\n",
        "    f.write(real_env)"
      ],
      "metadata": {
        "id": "Vme_Wn9Vn0PF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gitignore_content = \"\"\"\n",
        "# Secrets\n",
        ".env\n",
        "*.env\n",
        "secrets.json\n",
        "config.json\n",
        "\n",
        "# Other files...\n",
        "\"\"\"\n",
        "with open('.gitignore', 'w') as f:\n",
        "    f.write(gitignore_content)"
      ],
      "metadata": {
        "id": "mie311Bon-Ba"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}